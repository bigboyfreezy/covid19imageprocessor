{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bigboyfreezy/covid19imageprocessor/blob/main/COVID19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY4HtL5mp7fM",
        "outputId": "8bcadc16-14a4-4f50-de3c-5f0b572c1f18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'datasets'...\n",
            "remote: Enumerating objects: 2301, done.\u001b[K\n",
            "remote: Total 2301 (delta 0), reused 0 (delta 0), pack-reused 2301\u001b[K\n",
            "Receiving objects: 100% (2301/2301), 1.31 GiB | 14.08 MiB/s, done.\n",
            "Checking out files: 100% (2295/2295), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/education454/datasets.git\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **IMAGE PROCESSING OF COVID19 XRAYS USING CONVOLUTION NEURAL NETWORK**"
      ],
      "metadata": {
        "id": "xOJHy2uTnyQ_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-iJQaVosKDB"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator   #represents image in matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation,Dropout,Flatten,Dense\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras import backend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mX5Y1Z2yqeMQ"
      },
      "outputs": [],
      "source": [
        "# Specify images sizes\n",
        "img_width, img_height = 200, 200\n",
        "import os\n",
        "train_data_dir = os.path.join('/content/drive/My Drive/Data/train')\n",
        "validation_dir = os.path.join('/content/drive/My Drive/Data/test')\n",
        "nb_train_sample = 1811\n",
        "nb_validation_sample = 485\n",
        "ephocs = 5\n",
        "batch_size=64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5IaLUKLtEbQ"
      },
      "outputs": [],
      "source": [
        "# # Lets see the images\n",
        "# import glob\n",
        "# from IPython.display import Image, display\n",
        "# for imageName in glob.glob('/content/drive/My Drive/Data/train/COVID19/*'):\n",
        "#      display(Image(filename=imageName))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bz26q-5Q7U1R",
        "outputId": "6e42e745-d41b-4479-fc11-cebd20dae6de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "545\n"
          ]
        }
      ],
      "source": [
        "directory_path = '/content/drive/My Drive/Data/train/COVID19'\n",
        "No_of_files = len(os.listdir(directory_path))\n",
        "print(No_of_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8_-RS9StQkB"
      },
      "outputs": [],
      "source": [
        "# Channels of images RGB\n",
        "# img_width, image_width, 3\n",
        "\n",
        "# This code is often seen in deep learning frameworks like TensorFlow or Keras to handle differences in data format conventions.\n",
        "# In 'channels_first', the color channels are the first dimension of the input tensor,\n",
        "# while in 'channels_last', the color channels are the last dimension. This condition ensures that the input_shape is defined correctly based on the chosen data format.\n",
        "if backend.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRSC5k37tXK4"
      },
      "outputs": [],
      "source": [
        "# Create a neural network\n",
        "model = Sequential()\n",
        "# Input layer\n",
        "model.add(Conv2D(64, (2,2), input_shape= input_shape))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "# hidden 1\n",
        "model.add(Conv2D(64, (2,2)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "# hidden 2\n",
        "model.add(Conv2D(64, (2,2)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "# hiiden layer\n",
        "model.add(Flatten())  # reduces large arrays to single\n",
        "model.add(Dense(64))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))  #  removes some neurons completely\n",
        "\n",
        "# output\n",
        "model.add(Dense(1))\n",
        "model.add(Activation(\"sigmoid\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean Squared Error (MSE): Used in regression tasks, MSE measures the average squared difference between predicted and actual values. It is suitable for tasks where you want to minimize the variance.\n",
        "\n",
        "Binary Cross-Entropy (Log Loss): Used in binary classification problems, it measures the dissimilarity between predicted and actual binary labels (0 or 1).\n",
        "\n",
        "Categorical Cross-Entropy: Used in multiclass....More than two classification problems, it measures the dissimilarity between predicted class probabilities and actual class labels.\n",
        "\n",
        "Sparse Categorical Cross-Entropy: Similar to categorical cross-entropy, but suitable for problems with sparse labels (e.g., text classification)\n"
      ],
      "metadata": {
        "id": "Nh4LWvrrBKr9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stochastic Gradient Descent (SGD): The most fundamental optimizer. It updates model parameters with gradients computed from a random subset of the training data (mini-batch) at each iteration. SGD can be slow and may have trouble escaping local minima.\n",
        "\n",
        "Momentum: This optimizer builds on SGD by adding a momentum term, which helps the optimization process converge faster and dampens oscillations.\n",
        "\n",
        "RMSprop: RMSprop is another adaptive learning rate optimizer that mitigates the vanishing learning rate problem by using a moving average of squared gradients.\n",
        "\n",
        "Adam (Adaptive Moment Estimation): Adam combines the benefits of momentum and RMSprop. It adapts learning rates for each parameter and maintains both first-order (mean) and second-order (uncentered variance) moments of the gradients."
      ],
      "metadata": {
        "id": "HWVzyguZCPCD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZN-pC_hKtqR6"
      },
      "outputs": [],
      "source": [
        "# compile the model\n",
        "model.compile(loss = \"binary_crossentropy\", optimizer='adam', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keras Image Preprocessing: scaling image pixels\n",
        "for training"
      ],
      "metadata": {
        "id": "ga8--WzjG_IS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNBDBXRhtwk0",
        "outputId": "32d9070a-7556-4cdb-9512-a4e5a7210a6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1811 images belonging to 2 classes.\n",
            "Found 484 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Prepare data to fit the model\n",
        "# shear range helps computer see images from different angles\n",
        "# this is how a computer would zoom\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1./ 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "# test datya\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale = 1./ 255\n",
        ")\n",
        "# Create genrators\n",
        "train_generator =  train_datagen.flow_from_directory(\n",
        "      train_data_dir,\n",
        "      target_size=(img_width, img_height),\n",
        "      batch_size=batch_size,\n",
        "      class_mode='binary'\n",
        ")\n",
        "\n",
        "# Create genrators\n",
        "test_generator =  test_datagen.flow_from_directory(\n",
        "      validation_dir,\n",
        "      target_size=(img_width, img_height),\n",
        "      batch_size=batch_size,\n",
        "      class_mode='binary'\n",
        ")\n",
        "\n",
        "# fit data to model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wmMDkj55DPV",
        "outputId": "e4442cde-b197-4c26-a3be-ff7450a357c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "29/29 [==============================] - 488s 17s/step - loss: 0.5326 - accuracy: 0.7350 - val_loss: 0.2421 - val_accuracy: 0.9174\n",
            "Epoch 2/5\n",
            "29/29 [==============================] - 65s 2s/step - loss: 0.2245 - accuracy: 0.9061 - val_loss: 0.1376 - val_accuracy: 0.9545\n",
            "Epoch 3/5\n",
            "29/29 [==============================] - 67s 2s/step - loss: 0.1895 - accuracy: 0.9337 - val_loss: 0.1417 - val_accuracy: 0.9545\n",
            "Epoch 4/5\n",
            "29/29 [==============================] - 65s 2s/step - loss: 0.1594 - accuracy: 0.9442 - val_loss: 0.1340 - val_accuracy: 0.9566\n",
            "Epoch 5/5\n",
            "29/29 [==============================] - 62s 2s/step - loss: 0.1334 - accuracy: 0.9597 - val_loss: 0.1057 - val_accuracy: 0.9649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs = 5,\n",
        "    validation_data = test_generator\n",
        ")\n",
        "\n",
        "\n",
        "model.save('ImageClassifier.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPl9D9Fet0KN",
        "outputId": "af9eaddf-5450-425e-d2b5-ce54ca3c2865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 213ms/step\n",
            "Predicted Class: 0.0416259\n",
            "This X-RAY contains Covid\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import load_model\n",
        "# Load saved Model\n",
        "model = load_model('ImageClassifier.h5')\n",
        "# Upload an Image in the google drive - this is the image you want the model to predict for you\n",
        "image = load_img('/content/co2.jpg', target_size=(200, 200))\n",
        "img = np.array(image)\n",
        "img = img / 255.0 # reshape the image\n",
        "img = img.reshape(1,200,200,3)\n",
        "label = model.predict(img)\n",
        "print(\"Predicted Class:\", label[0][0])\n",
        "\n",
        "# a value below 0 to 0.25 means its Coovid\n",
        "# a value above 0.8 to 1 means its Not covid\n",
        "# any other value the model is not sure what is contained in the Image\n",
        "\n",
        "if label[0][0] < 0.25:\n",
        "   print(\"This X-RAY contains Covid\")\n",
        "elif label[0][0] > 0.80:\n",
        "  print(\"Normal XRAY\")\n",
        "else:\n",
        "  print(\"Not Sure\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1eBSn-NGiePp-8uYweqHH_AFCkxPHzews",
      "authorship_tag": "ABX9TyO/dqMeALOgMNbVmv2rOm4I",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}